{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('corpus.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)\n",
    "df = df.iloc[:,[1,0]]\n",
    "df.columns = ['article_id','article_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barack Obama_2010</td>\n",
       "      <td>Madam Speaker, Vice President Biden, Members o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama_2011</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barack Obama_2012</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barack Obama_2013</td>\n",
       "      <td>\\r\\nMr. Speaker, Mr. Vice President, members o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barack Obama_2014</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          article_id                                       article_text\n",
       "0  Barack Obama_2010  Madam Speaker, Vice President Biden, Members o...\n",
       "1  Barack Obama_2011  Mr. Speaker, Mr. Vice President, members of Co...\n",
       "2  Barack Obama_2012   Mr. Speaker, Mr. Vice President, members of C...\n",
       "3  Barack Obama_2013  \\r\\nMr. Speaker, Mr. Vice President, members o...\n",
       "4  Barack Obama_2014  Mr. Speaker, Mr. Vice President, Members of Co..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize one single President Obama Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one single article from our list above\n",
    "df = df[df['article_id'] == 'Barack Obama_2011']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = []\n",
    "for s in df['article_text']:\n",
    "  sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word vectors\n",
    "# download glove here https://nlp.stanford.edu/projects/glove/ if !wget doesn't work\n",
    "import numpy as np\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "# make alphabets lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alanl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "  if len(i) != 0:\n",
    "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "  else:\n",
    "    v = np.zeros((100,))\n",
    "  sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "  for j in range(len(sentences)):\n",
    "    if i != j:\n",
    "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As Kathy said, “I hope it tells them to never give up.”\n",
      "\r\n",
      "      If we take these steps -– if we raise expectations for every child, and give them the best possible chance at an education, from the day they are born until the last job they take –- we will reach the goal that I set two years ago:  By the end of the decade, America will once again have the highest proportion of college graduates in the world.\n",
      "We’re a nation that says, “I might not have a lot of money, but I have this great idea for a new company.”  “I might not come from a family of college graduates, but I will be the first to get my degree.”  “I might not know those people in trouble, but I think I can help them, and I need to try.”  “I’m not sure how we’ll reach that better place beyond the horizon, but I know we’ll get there.\n",
      "Thirty years ago, we couldn’t know that something called the Internet would lead to an economic revolution.\n"
     ]
    }
   ],
   "source": [
    "# Extract top 3 sentences as the summary\n",
    "for i in range(3):\n",
    "  print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize All President Trump State of Union Address speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barack Obama_2010</td>\n",
       "      <td>Madam Speaker, Vice President Biden, Members o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama_2011</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barack Obama_2012</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barack Obama_2013</td>\n",
       "      <td>\\r\\nMr. Speaker, Mr. Vice President, members o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barack Obama_2014</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barack Obama_2015</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barack Obama_2016</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bill Clinton_1994</td>\n",
       "      <td>Thank you very much. Mr. Speaker, Mr. Presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bill Clinton_1995</td>\n",
       "      <td>Mr. President, Mr. Speaker, members of the 104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bill Clinton_1996</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bill Clinton_1997</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bill Clinton_1998</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bill Clinton_1999</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bill Clinton_2000</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Donald Trump_2018</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Donald Trump_2019</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>George H.W. Bush_1990</td>\n",
       "      <td>Mr. President, Mr. Speaker, members of the Uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>George H.W. Bush_1991</td>\n",
       "      <td>Mr. President and Mr. Speaker and members of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>George H.W. Bush_1992</td>\n",
       "      <td>Mr. Speaker and Mr. President, distinguished m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>George W. Bush_2002</td>\n",
       "      <td>Thank you very much. Mr. Speaker, Vice Preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>George W. Bush_2003</td>\n",
       "      <td>Mr. Speaker, Vice President Cheney, members of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>George W. Bush_2004</td>\n",
       "      <td>Mr. Speaker, Vice President Cheney, members of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>George W. Bush_2005</td>\n",
       "      <td>Mr. Speaker, Vice President Cheney, members of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>George W. Bush_2006</td>\n",
       "      <td>Thank you all. Mr. Speaker, Vice President Che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>George W. Bush_2007</td>\n",
       "      <td>Thank you very much. And tonight I have the hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>George W. Bush_2008</td>\n",
       "      <td>Madam Speaker, Vice President Cheney, members ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gerald Ford_1975</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gerald Ford_1976</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gerald Ford_1977</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, members of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Jimmy Carter_1978</td>\n",
       "      <td>Mr. President, Mr. Speaker, members of the 95t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jimmy Carter_1979</td>\n",
       "      <td>Mr. President, Mr. Speaker, members of the 96t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Jimmy Carter_1980</td>\n",
       "      <td>Mr. President, Mr. Speaker, members of the 96t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>John F. Kennedy_1961</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>John F. Kennedy_1962</td>\n",
       "      <td>Mr. Vice President, my old colleague from Mass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>John F. Kennedy_1963</td>\n",
       "      <td>Mr. Vice President, Mr. Speaker, Members of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lyndon B. Johnson_1964</td>\n",
       "      <td>Mr. Speaker, Mr. President, members of the Hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Lyndon B. Johnson_1965</td>\n",
       "      <td>Mr. Speaker, Mr. President, members of the Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lyndon B. Johnson_1966</td>\n",
       "      <td>Mr. Speaker, Mr. President, members of the Hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lyndon B. Johnson_1967</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, distinguished...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Lyndon B. Johnson_1968</td>\n",
       "      <td>Mr. Speaker, Mr. President, Members of the C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Lyndon B. Johnson_1969</td>\n",
       "      <td>Mr. Speaker, Mr. President, Members of the C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Richard M. Nixon_1970</td>\n",
       "      <td>Mr. Speaker, Mr. President, my colleagues in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Richard M. Nixon_1971</td>\n",
       "      <td>Mr. Speaker, Mr. President, my colleagues in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Richard M. Nixon_1972</td>\n",
       "      <td>Mr. Speaker, Mr. President, my colleagues in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Richard M. Nixon_1974</td>\n",
       "      <td>Mr. Speaker, Mr. President, my colleagues in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ronald Reagan_1982</td>\n",
       "      <td>Mr. Speaker, Mr. President, distinguished Memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ronald Reagan_1983</td>\n",
       "      <td>Mr. Speaker, Mr. President, distinguished Memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ronald Reagan_1984</td>\n",
       "      <td>Mr. Speaker, Mr. President, distinguished memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ronald Reagan_1985</td>\n",
       "      <td>Mr. Speaker, Mr. President, distinguished Memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Ronald Reagan_1986</td>\n",
       "      <td>Mr. Speaker, Mr. President, distinguished Memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Ronald Reagan_1987</td>\n",
       "      <td>Mr. Speaker, Mr. President, distinguished Memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ronald Reagan_1988</td>\n",
       "      <td>Mr. Speaker, Mr. President, and distinguished ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                article_id                                       article_text\n",
       "0        Barack Obama_2010  Madam Speaker, Vice President Biden, Members o...\n",
       "1        Barack Obama_2011  Mr. Speaker, Mr. Vice President, members of Co...\n",
       "2        Barack Obama_2012   Mr. Speaker, Mr. Vice President, members of C...\n",
       "3        Barack Obama_2013  \\r\\nMr. Speaker, Mr. Vice President, members o...\n",
       "4        Barack Obama_2014  Mr. Speaker, Mr. Vice President, Members of Co...\n",
       "5        Barack Obama_2015  Mr. Speaker, Mr. Vice President, Members of Co...\n",
       "6        Barack Obama_2016  Mr. Speaker, Mr. Vice President, Members of Co...\n",
       "7        Bill Clinton_1994  Thank you very much. Mr. Speaker, Mr. Presiden...\n",
       "8        Bill Clinton_1995  Mr. President, Mr. Speaker, members of the 104...\n",
       "9        Bill Clinton_1996  Mr. Speaker, Mr. Vice President, members of th...\n",
       "10       Bill Clinton_1997  Mr. Speaker, Mr. Vice President, members of th...\n",
       "11       Bill Clinton_1998  Mr. Speaker, Mr. Vice President, members of th...\n",
       "12       Bill Clinton_1999  Mr. Speaker, Mr. Vice President, members of Co...\n",
       "13       Bill Clinton_2000  Mr. Speaker, Mr. Vice President, members of Co...\n",
       "14       Donald Trump_2018  Mr. Speaker, Mr. Vice President, Members of Co...\n",
       "15       Donald Trump_2019  Madam Speaker, Mr. Vice President, Members of ...\n",
       "16   George H.W. Bush_1990  Mr. President, Mr. Speaker, members of the Uni...\n",
       "17   George H.W. Bush_1991  Mr. President and Mr. Speaker and members of t...\n",
       "18   George H.W. Bush_1992  Mr. Speaker and Mr. President, distinguished m...\n",
       "19     George W. Bush_2002  Thank you very much. Mr. Speaker, Vice Preside...\n",
       "20     George W. Bush_2003  Mr. Speaker, Vice President Cheney, members of...\n",
       "21     George W. Bush_2004  Mr. Speaker, Vice President Cheney, members of...\n",
       "22     George W. Bush_2005  Mr. Speaker, Vice President Cheney, members of...\n",
       "23     George W. Bush_2006  Thank you all. Mr. Speaker, Vice President Che...\n",
       "24     George W. Bush_2007  Thank you very much. And tonight I have the hi...\n",
       "25     George W. Bush_2008  Madam Speaker, Vice President Cheney, members ...\n",
       "26        Gerald Ford_1975  Mr. Speaker, Mr. Vice President, members of th...\n",
       "27        Gerald Ford_1976  Mr. Speaker, Mr. Vice President, members of th...\n",
       "28        Gerald Ford_1977  Mr. Speaker, Mr. Vice President, members of th...\n",
       "29       Jimmy Carter_1978  Mr. President, Mr. Speaker, members of the 95t...\n",
       "30       Jimmy Carter_1979  Mr. President, Mr. Speaker, members of the 96t...\n",
       "31       Jimmy Carter_1980  Mr. President, Mr. Speaker, members of the 96t...\n",
       "32    John F. Kennedy_1961  Mr. Speaker, Mr. Vice President, Members of th...\n",
       "33    John F. Kennedy_1962  Mr. Vice President, my old colleague from Mass...\n",
       "34    John F. Kennedy_1963  Mr. Vice President, Mr. Speaker, Members of th...\n",
       "35  Lyndon B. Johnson_1964  Mr. Speaker, Mr. President, members of the Hou...\n",
       "36  Lyndon B. Johnson_1965  Mr. Speaker, Mr. President, members of the Con...\n",
       "37  Lyndon B. Johnson_1966  Mr. Speaker, Mr. President, members of the Hou...\n",
       "38  Lyndon B. Johnson_1967  Mr. Speaker, Mr. Vice President, distinguished...\n",
       "39  Lyndon B. Johnson_1968    Mr. Speaker, Mr. President, Members of the C...\n",
       "40  Lyndon B. Johnson_1969    Mr. Speaker, Mr. President, Members of the C...\n",
       "41   Richard M. Nixon_1970  Mr. Speaker, Mr. President, my colleagues in t...\n",
       "42   Richard M. Nixon_1971  Mr. Speaker, Mr. President, my colleagues in t...\n",
       "43   Richard M. Nixon_1972  Mr. Speaker, Mr. President, my colleagues in t...\n",
       "44   Richard M. Nixon_1974  Mr. Speaker, Mr. President, my colleagues in t...\n",
       "45      Ronald Reagan_1982  Mr. Speaker, Mr. President, distinguished Memb...\n",
       "46      Ronald Reagan_1983  Mr. Speaker, Mr. President, distinguished Memb...\n",
       "47      Ronald Reagan_1984  Mr. Speaker, Mr. President, distinguished memb...\n",
       "48      Ronald Reagan_1985  Mr. Speaker, Mr. President, distinguished Memb...\n",
       "49      Ronald Reagan_1986  Mr. Speaker, Mr. President, distinguished Memb...\n",
       "50      Ronald Reagan_1987  Mr. Speaker, Mr. President, distinguished Memb...\n",
       "51      Ronald Reagan_1988  Mr. Speaker, Mr. President, and distinguished ..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('corpus.pkl')\n",
    "df = df.reset_index(drop = True)\n",
    "df = df.iloc[:,[1,0]]\n",
    "df.columns = ['article_id','article_text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['article_id'].str.contains(\"Donald Trump\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Donald Trump_2018</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Donald Trump_2019</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           article_id                                       article_text\n",
       "14  Donald Trump_2018  Mr. Speaker, Mr. Vice President, Members of Co...\n",
       "15  Donald Trump_2019  Madam Speaker, Mr. Vice President, Members of ..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for s in df['article_text']:\n",
    "  sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "# make alphabets lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "  if len(i) != 0:\n",
    "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "  else:\n",
    "    v = np.zeros((100,))\n",
    "  sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "  for j in range(len(sentences)):\n",
    "    if i != j:\n",
    "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each day since, we have gone forward with a clear vision and a righteous mission—to make America great again for all Americans.\n",
      "It is time to begin moving towards a merit-based immigration system—one that admits people who are skilled, who want to work, who will contribute to our society, and who will love and respect our country.\n",
      "We do not know whether we will achieve an agreement—but we do know that after two decades of war, the hour has come to at least try for peace.\n"
     ]
    }
   ],
   "source": [
    "# Extract top 3 sentences as the summary\n",
    "for i in range(3):\n",
    "  print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn this into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the text summarization function\n",
    "def summarize_text(x_df):\n",
    "    # extract the sentences\n",
    "    sentences = []\n",
    "    for s in x_df['article_text']:\n",
    "        sentences.append(sent_tokenize(s))\n",
    "    sentences = [y for x in sentences for y in x]\n",
    "    \n",
    "    # clean the data\n",
    "    clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "    clean_sentences = [s.lower() for s in clean_sentences]\n",
    "    clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]    \n",
    "    sentence_vectors = []\n",
    "    for i in clean_sentences:\n",
    "        if len(i) != 0:\n",
    "            v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "        else:\n",
    "            v = np.zeros((100,))\n",
    "        sentence_vectors.append(v)\n",
    "        \n",
    "    # similarity matrix\n",
    "    sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "    # Extract top 3 sentences as the summary\n",
    "    textbox = []\n",
    "    for i in range(3):\n",
    "        textbox.append(ranked_sentences[i][1])\n",
    "    return(textbox)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Each day since, we have gone forward with a clear vision and a righteous mission—to make America great again for all Americans.',\n",
       " 'It is time to begin moving towards a merit-based immigration system—one that admits people who are skilled, who want to work, who will contribute to our society, and who will love and respect our country.',\n",
       " 'We do not know whether we will achieve an agreement—but we do know that after two decades of war, the hour has come to at least try for peace.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_text(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
